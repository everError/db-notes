# 🔍 벡터 데이터베이스 임베딩 시 메트릭 유형 정리

## 1. 개요

벡터 데이터베이스(Vector Database)는 임베딩(Embedding)된 벡터 간의 **유사도(Similarity)** 또는 **거리(Distance)**를 기반으로 검색, 분류, 추천 등의 연산을 수행한다.
이때 "메트릭 유형(metric type)"은 **벡터 간의 유사도를 어떻게 측정할 것인지**를 결정하는 핵심 파라미터이다.

대표적인 메트릭 유형은 다음과 같다:

| 메트릭 이름                               | 의미                     | 주요 사용 사례               |
| ------------------------------------ | ---------------------- | ---------------------- |
| **L2 (Euclidean Distance)**          | 유클리드 거리(두 점 사이의 직선 거리) | 공간적 거리 계산, 좌표 기반 데이터   |
| **IP (Inner Product / Dot Product)** | 내적 기반 유사도              | 문장/단어 임베딩, 언어모델 등      |
| **Cosine Similarity**                | 코사인 각도 기반 유사도          | 텍스트/문서 유사도, NLP        |
| **Manhattan (L1 Distance)**          | 절대값 합 거리               | 희소 벡터, 분포 차이 비교        |
| **Hamming Distance**                 | 비트 단위 불일치 개수           | 해시 벡터, binary encoding |

---

## 2. 주요 메트릭 유형별 상세 설명

### 🟢 2.1 L2 (Euclidean Distance)

* **공식:**
  [
  d(\mathbf{a}, \mathbf{b}) = \sqrt{\sum_i (a_i - b_i)^2}
  ]
* **특징:**

  * 두 벡터 간의 실제 "거리"를 계산.
  * 값이 작을수록 두 벡터가 가깝다는 의미.
* **장점:**

  * 직관적이며 수학적으로 간단.
  * 공간적 의미가 명확함.
* **단점:**

  * 벡터의 크기에 영향을 받음.
  * 방향이 같더라도 크기 차이로 인해 거리가 커질 수 있음.
* **주요 사용처:**

  * 이미지, 좌표 기반 데이터, 3D 포인트 클라우드.

---

### 🟡 2.2 IP (Inner Product, Dot Product)

* **공식:**
  [
  s(\mathbf{a}, \mathbf{b}) = \sum_i a_i \cdot b_i
  ]
* **특징:**

  * 내적이 클수록 두 벡터가 같은 방향을 가리킨다는 의미.
  * 거리보다는 유사도(Similarity)를 직접 계산.
* **장점:**

  * 임베딩 벡터가 정규화되지 않아도 방향성을 반영.
  * 신경망 임베딩과 상성이 좋음.
* **단점:**

  * 크기가 큰 벡터가 과도한 영향력을 가질 수 있음.
* **주요 사용처:**

  * 문장, 단어 임베딩 (BERT, Sentence-BERT, OpenAI Embeddings 등)
  * LLM 기반 RAG 시스템의 기본 유사도 지표로 자주 사용됨.

---

### 🔵 2.3 Cosine Similarity

* **공식:**
  [
  \text{cos_sim}(\mathbf{a}, \mathbf{b}) = \frac{\mathbf{a} \cdot \mathbf{b}}{|\mathbf{a}| |\mathbf{b}|}
  ]
* **특징:**

  * 두 벡터 간의 **각도(방향)**를 기반으로 유사도 계산.
  * -1 ~ 1 사이의 값을 가짐 (1: 완전히 동일 방향)
* **장점:**

  * 벡터의 크기에 영향을 받지 않음.
  * 임베딩 벡터의 상대적 의미 비교에 적합.
* **단점:**

  * 크기 정보를 완전히 무시하므로, “양의 강도” 차이를 구분하기 어렵다.
* **주요 사용처:**

  * 텍스트 임베딩, RAG, 문서 검색, 문장 유사도 분석.
  * 대부분의 NLP 임베딩에서 기본 선택.

---

### 🟠 2.4 Manhattan (L1 Distance)

* **공식:**
  [
  d(\mathbf{a}, \mathbf{b}) = \sum_i |a_i - b_i|
  ]
* **특징:**

  * 각 차원의 절대 거리의 합을 계산.
* **장점:**

  * 이상치(outlier)에 덜 민감함.
  * 희소(sparse)한 데이터에 강함.
* **단점:**

  * 고차원에서는 L2보다 분별력이 떨어질 수 있음.
* **주요 사용처:**

  * 희소 벡터, 분포 차이를 비교할 때.

---

### 🔴 2.5 Hamming Distance

* **공식:**
  [
  d(\mathbf{a}, \mathbf{b}) = \text{Number of bits where } a_i \neq b_i
  ]
* **특징:**

  * 두 이진 벡터(binary vector) 간의 차이 개수를 계산.
* **장점:**

  * 계산이 매우 빠름.
  * 해시 기반 근사 검색(LSH)에서 활용.
* **단점:**

  * 실수(float)형 벡터에는 직접 적용 불가.
* **주요 사용처:**

  * 해시 벡터, 이진 인코딩된 검색 시스템.

---

## 3. 비교 요약표

| 메트릭                    | 수식 기반  | 결과 해석   | 크기 영향   | 계산 복잡도 | 주요 사용 분야    |
| ---------------------- | ------ | ------- | ------- | ------ | ----------- |
| **L2 (Euclidean)**     | 거리     | 작을수록 유사 | ✅ 영향 큼  | 보통     | 이미지, 공간 데이터 |
| **Inner Product (IP)** | 내적     | 클수록 유사  | ✅ 영향 큼  | 빠름     | 문장, 단어 임베딩  |
| **Cosine Similarity**  | 각도     | 클수록 유사  | ❌ 없음    | 빠름     | 텍스트, 문서 검색  |
| **Manhattan (L1)**     | 절댓값 합  | 작을수록 유사 | ✅ 영향 있음 | 빠름     | 희소 데이터      |
| **Hamming**            | 비트 불일치 | 작을수록 유사 | ❌ 없음    | 매우 빠름  | 해시 벡터       |

---

## 4. 선택 가이드

| 상황                       | 추천 메트릭                 | 이유                 |
| ------------------------ | ---------------------- | ------------------ |
| 텍스트, 문장, 문서 임베딩          | **Cosine Similarity**  | 방향성 중심 비교에 적합      |
| 언어 모델(LLM) 임베딩 기반 검색     | **IP (Inner Product)** | 내적 기반 학습 모델과 호환    |
| 이미지 / 좌표 기반 벡터           | **L2 Distance**        | 물리적 거리 기반이 자연스러움   |
| 희소 벡터 (Sparse Embedding) | **Manhattan Distance** | L1이 이상치에 덜 민감      |
| Binary Hash 기반 검색        | **Hamming Distance**   | 매우 빠른 근사 유사도 계산 가능 |

---

## 5. 실무 팁

* **Cosine vs Inner Product**

  * 두 메트릭은 `정규화(normalization)` 여부에 따라 사실상 동일해질 수 있다.
    즉, 벡터를 단위벡터로 정규화한 후 Inner Product를 사용하면 Cosine과 같다.
* **Milvus / Chroma / Pinecone 등에서는 보통 다음 옵션 제공:**

  * `L2`
  * `IP`
  * `COSINE`
* **OpenAI, Sentence-BERT, Instructor 등 대부분의 임베딩 모델 → Cosine 또는 IP에 최적화.**
* **임베딩 모델과의 궁합 확인 필수**

  * 예:

    * `text-embedding-3-large`: **Cosine**
    * `OpenAI ada-002`: **Cosine**
    * `CLIP`: **Inner Product (Dot Product)**
    * `FAISS`: `L2` 또는 `IP` 선택 가능

---

## 6. 결론

* 메트릭 유형은 단순한 설정값이 아니라, **검색 결과 품질을 결정짓는 핵심 변수**이다.
* 모델이 어떤 방식으로 임베딩을 학습했는지(크기 or 방향 기반)에 따라 **L2 / IP / Cosine** 중 하나를 신중히 선택해야 한다.
* 일반적으로:

  * **NLP/RAG → Cosine or IP**
  * **Vision/Geometry → L2**